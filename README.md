# Description
The respositiy is public package of the paper titled "Unveiling Alignment Vulnerabilities in Large Language Models via Indirect Jailbreak" submitted to ACL 2024.

IJBR Architecture:  
![Image text](https://github.com/czycurefun/IJBR/blob/main/fig/final_artifactureV2.0.png)
- OSG.py is to generate offensive strategies  
- jailbreak.py is to jailbreak LLM



# Run the code
python OSG.py  
python jailbreak.py  







